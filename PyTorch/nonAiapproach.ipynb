{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alapa\\funiegan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alapa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/alapa/funiegan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Contrast: 68.71, Noise Level: 289.04\n",
      "Applying dehazing...\n",
      "Restoring red channel...\n",
      "Processed image saved to C:/Users/alapa/funiegan/nonAIprocessed/processed_underwater1.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "\n",
    "def calculate_image_metrics(image):\n",
    "    \"\"\"Calculate basic metrics to assess image quality.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    contrast = gray.std()  # Standard deviation as a measure of contrast\n",
    "    noise_level = np.mean(cv2.Laplacian(gray, cv2.CV_64F)**2)  # Variance of Laplacian\n",
    "    return contrast, noise_level\n",
    "\n",
    "def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "    \"\"\"Apply CLAHE for contrast enhancement.\"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    l = clahe.apply(l)\n",
    "    enhanced = cv2.merge((l, a, b))\n",
    "    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def denoise_image(image, method=\"bilateral\", d=9, sigma_color=75, sigma_space=75):\n",
    "    \"\"\"Denoise the image using the specified method.\"\"\"\n",
    "    if method == \"bilateral\":\n",
    "        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n",
    "    elif method == \"median\":\n",
    "        return cv2.medianBlur(image, 5)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported denoising method.\")\n",
    "\n",
    "def dehaze_image(image, beta=1.0):\n",
    "    \"\"\"Simple dehazing using dark channel prior.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    dark_channel = cv2.min(cv2.min(image[:, :, 0], image[:, :, 1]), image[:, :, 2])\n",
    "    transmission = 1 - beta * (dark_channel / 255)\n",
    "    transmission = np.clip(transmission, 0.1, 1)\n",
    "    result = image / transmission[:, :, None]\n",
    "    return np.uint8(np.clip(result, 0, 255))\n",
    "\n",
    "def restore_red_channel(image, red_boost=1.5):\n",
    "    \"\"\"Restore the red channel for underwater images.\"\"\"\n",
    "    b, g, r = cv2.split(image)\n",
    "    r = cv2.addWeighted(r, red_boost, 0, 0, 0)\n",
    "    return cv2.merge((b, g, r))\n",
    "\n",
    "def process_underwater_image(image_path, save_path=None):\n",
    "    \"\"\"Main pipeline for underwater image processing.\"\"\"\n",
    "    # Read input image\n",
    "    image = cv2.imread(image_path)\n",
    "    original_image = image.copy()\n",
    "\n",
    "    # Step 1: Assess image quality\n",
    "    contrast, noise_level = calculate_image_metrics(image)\n",
    "    print(f\"Initial Contrast: {contrast:.2f}, Noise Level: {noise_level:.2f}\")\n",
    "\n",
    "    # Step 2: Preprocessing - Denoising\n",
    "    if noise_level > 1000:  # Threshold for high noise\n",
    "        print(\"Applying denoising...\")\n",
    "        image = denoise_image(image, method=\"bilateral\")\n",
    "\n",
    "    # Step 3: Enhancement - Dehazing\n",
    "    print(\"Applying dehazing...\")\n",
    "    image = dehaze_image(image)\n",
    "\n",
    "    # Step 4: Enhancement - Contrast Adjustment\n",
    "    if contrast < 50:  # Threshold for low contrast\n",
    "        print(\"Applying CLAHE for contrast enhancement...\")\n",
    "        image = apply_clahe(image)\n",
    "\n",
    "    # Step 5: Postprocessing - Red Channel Restoration\n",
    "    print(\"Restoring red channel...\")\n",
    "    image = restore_red_channel(image)\n",
    "\n",
    "    # Save and return the processed image\n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, image)\n",
    "        print(f\"Processed image saved to {save_path}\")\n",
    "\n",
    "    return original_image, image\n",
    "\n",
    "# Example usage\n",
    "#input_image = \"C:/Users/alapa/funiegan/EUVP/Paired/underwater_dark/trainA/264286_00007889.jpg\"  # Replace with your image path\n",
    "input_image = \"C:/Users/alapa/imageupscaler/upscalar(ESRGAN)/results/RealESRGAN_x8.pth/output_264286_00007889.jpg\"\n",
    "output_image = \"C:/Users/alapa/funiegan/nonAIprocessed/processed_underwater1.jpg\"\n",
    "\n",
    "original, processed = process_underwater_image(input_image, save_path=output_image)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Original Image\", original)\n",
    "cv2.imshow(\"Processed Image\", processed)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Contrast: 68.71, Noise Level: 289.04\n",
      "Applying dehazing...\n",
      "Restoring red channel...\n",
      "Processed image saved to C:/Users/alapa/funiegan/nonAIprocessed/processed_underwater1.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_image_metrics(image):\n",
    "    \"\"\"Calculate basic metrics to assess image quality.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    contrast = gray.std()  # Standard deviation as a measure of contrast\n",
    "    noise_level = np.mean(cv2.Laplacian(gray, cv2.CV_64F)**2)  # Variance of Laplacian\n",
    "    return contrast, noise_level\n",
    "\n",
    "def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "    \"\"\"Apply CLAHE for contrast enhancement.\"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    l = clahe.apply(l)\n",
    "    enhanced = cv2.merge((l, a, b))\n",
    "    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def denoise_image(image, method=\"bilateral\", d=9, sigma_color=75, sigma_space=75):\n",
    "    \"\"\"Denoise the image using the specified method.\"\"\"\n",
    "    if method == \"bilateral\":\n",
    "        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n",
    "    elif method == \"median\":\n",
    "        return cv2.medianBlur(image, 5)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported denoising method.\")\n",
    "\n",
    "def dehaze_image(image, beta=0.9):\n",
    "    \"\"\"Simplified dehazing based on dark channel prior.\"\"\"\n",
    "    dark_channel = np.min(image, axis=2)\n",
    "    transmission = 1 - beta * (dark_channel / 255)\n",
    "    transmission = np.clip(transmission, 0.3, 1)  # Avoid division by zero\n",
    "    result = image / transmission[:, :, None]\n",
    "    return np.uint8(np.clip(result, 0, 255))\n",
    "\n",
    "def restore_red_channel(image, red_boost=1.2):\n",
    "    \"\"\"Restore the red channel for underwater images.\"\"\"\n",
    "    b, g, r = cv2.split(image)\n",
    "    r = np.clip(r * red_boost, 0, 255).astype(np.uint8)\n",
    "    return cv2.merge((b, g, r))\n",
    "\n",
    "def process_underwater_image(image_path, save_path=None, debug=False):\n",
    "    \"\"\"Main pipeline for underwater image processing.\"\"\"\n",
    "    # Read input image\n",
    "    image = cv2.imread(image_path)\n",
    "    original_image = image.copy()\n",
    "\n",
    "    # Step 1: Assess image quality\n",
    "    contrast, noise_level = calculate_image_metrics(image)\n",
    "    if debug:\n",
    "        print(f\"Initial Contrast: {contrast:.2f}, Noise Level: {noise_level:.2f}\")\n",
    "\n",
    "    # Step 2: Preprocessing - Denoising\n",
    "    if noise_level > 500:  # Adjusted threshold for high noise\n",
    "        if debug: print(\"Applying denoising...\")\n",
    "        image = denoise_image(image, method=\"bilateral\")\n",
    "\n",
    "    # Step 3: Enhancement - Dehazing\n",
    "    if debug: print(\"Applying dehazing...\")\n",
    "    image = dehaze_image(image)\n",
    "\n",
    "    # Step 4: Enhancement - Contrast Adjustment\n",
    "    if contrast < 40:  # Adjusted threshold for low contrast\n",
    "        if debug: print(\"Applying CLAHE for contrast enhancement...\")\n",
    "        image = apply_clahe(image)\n",
    "\n",
    "    # Step 5: Postprocessing - Red Channel Restoration\n",
    "    if debug: print(\"Restoring red channel...\")\n",
    "    image = restore_red_channel(image)\n",
    "\n",
    "    # Save and return the processed image\n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, image)\n",
    "        if debug: print(f\"Processed image saved to {save_path}\")\n",
    "\n",
    "    return original_image, image\n",
    "\n",
    "# Example usage\n",
    "#input_image = \"C:/Users/alapa/funiegan/EUVP/Paired/underwater_dark/trainA/264286_00007889.jpg\"  # Replace with your image path\n",
    "input_image = \"C:/Users/alapa/imageupscaler/upscalar(ESRGAN)/results/RealESRGAN_x8.pth/output_264286_00007889.jpg\"\n",
    "output_image = \"C:/Users/alapa/funiegan/nonAIprocessed/processed_underwater1.jpg\"\n",
    "# Enable debug mode for detailed output\n",
    "debug_mode = True\n",
    "\n",
    "# Process the image\n",
    "original, processed = process_underwater_image(input_image, save_path=output_image, debug=debug_mode)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow(\"Original Image\", original)\n",
    "cv2.imshow(\"Processed Image\", processed)\n",
    "cv2.waitKey(0)  # Automatically close after 5 seconds\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancing contrast...\n",
      "Correcting color...\n",
      "Denoising...\n",
      "Dehazing...\n",
      "Applying Super-Resolution...\n",
      "Processed image saved at C:/Users/alapa/funiegan/nonAIprocessed/processed_underwater2.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    \"\"\"Apply Multi-Scale Retinex (MSR) for illumination correction.\"\"\"\n",
    "    img_float = np.float32(image) + 1.0  # Convert to float for calculation\n",
    "    # Apply Gaussian blur and log operation for Retinex processing\n",
    "    retinex = np.log10(img_float) - np.log10(cv2.GaussianBlur(img_float, (81, 81), 30))\n",
    "    \n",
    "    # Clip to avoid excessive brightening\n",
    "    retinex = np.clip((retinex - np.min(retinex)) / (np.max(retinex) - np.min(retinex)) * 255, 0, 255)\n",
    "    return np.uint8(retinex)\n",
    "\n",
    "def color_correct(image, red_boost=1.1, blue_boost=1.1):\n",
    "    \"\"\"Correct color channels by boosting red and blue.\"\"\"\n",
    "    b, g, r = cv2.split(image)\n",
    "    \n",
    "    # Boost channels but clip values to avoid overexposure\n",
    "    r = np.clip(r * red_boost, 0, 255).astype(np.uint8)\n",
    "    b = np.clip(b * blue_boost, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return cv2.merge((b, g, r))\n",
    "\n",
    "def denoise(image):\n",
    "    \"\"\"Apply noise reduction using Non-Local Means Denoising.\"\"\"\n",
    "    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "\n",
    "def dehaze(image, beta=0.85):\n",
    "    \"\"\"Dehaze using Dark Channel Prior and a controlled transmission map.\"\"\"\n",
    "    # Dark channel computation (min across channels)\n",
    "    dark_channel = np.min(image, axis=2)\n",
    "    transmission = 1 - beta * (dark_channel / 255)\n",
    "    \n",
    "    # Clip the transmission to avoid over-enhancement\n",
    "    transmission = np.clip(transmission, 0.1, 1)  # Limit transmission to avoid extreme results\n",
    "    \n",
    "    # Apply dehazing using a physical model (adjust transmission to control effect)\n",
    "    dehazed = (image - 0.1) / transmission[:, :, None]  # Prevent extreme increase\n",
    "    dehazed = np.clip(dehazed, 0, 255)  # Clip to valid range\n",
    "    \n",
    "    return np.uint8(dehazed)\n",
    "\n",
    "def super_resolution(image, scale=2, model_path=\"nonAIprocessed/models/EDSR_x2.pb\"):\n",
    "    \"\"\"Apply Super-Resolution using OpenCV's DNN SuperRes.\"\"\"\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    sr.readModel(model_path)  # Load the pre-trained model\n",
    "    sr.setModel(\"edsr\", scale)  # Use the EDSR model with scaling factor\n",
    "    result = sr.upsample(image)\n",
    "\n",
    "    # Clip the result to ensure pixel values are within valid range\n",
    "    result = np.clip(result, 0, 255)\n",
    "    return result\n",
    "\n",
    "def process_underwater_image(image_path, save_path=None):\n",
    "    \"\"\"Full underwater image processing pipeline.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    original = image.copy()\n",
    "\n",
    "    # Step 1: Enhance contrast\n",
    "    print(\"Enhancing contrast...\")\n",
    "    image = enhance_contrast(image)\n",
    "    cv2.imshow(\"After Contrast Enhancement\", image)\n",
    "    \n",
    "    # Step 2: Color correction\n",
    "    print(\"Correcting color...\")\n",
    "    image = color_correct(image)\n",
    "    cv2.imshow(\"After Color Correction\", image)\n",
    "\n",
    "    # Step 3: Denoising\n",
    "    print(\"Denoising...\")\n",
    "    image = denoise(image)\n",
    "    cv2.imshow(\"After Denoising\", image)\n",
    "\n",
    "    # Step 4: Dehazing\n",
    "    print(\"Dehazing...\")\n",
    "    image = dehaze(image)\n",
    "    cv2.imshow(\"After Dehazing\", image)\n",
    "\n",
    "    # Step 5: Super-Resolution\n",
    "    print(\"Applying Super-Resolution...\")\n",
    "    image = super_resolution(image)\n",
    "    cv2.imshow(\"After Super-Resolution\", image)\n",
    "\n",
    "    # Final safeguard to ensure pixel values stay within the valid range\n",
    "    image = np.clip(image, 0, 255)\n",
    "    \n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, image)\n",
    "        print(f\"Processed image saved at {save_path}\")\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return original, image\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_image = \"C:/Users/alapa/funiegan/EUVP/Paired/underwater_dark/trainA/264286_00007889.jpg\"  # Replace with your image path\n",
    "#input_image = \"C:/Users/alapa/imageupscaler/upscalar(ESRGAN)/results/RealESRGAN_x8.pth/output_264286_00007889.jpg\"\n",
    "output_image = \"C:/Users/alapa/funiegan/nonAIprocessed/processed_underwater2.jpg\"\n",
    "\n",
    "original, processed = process_underwater_image(input_image, save_path=output_image)\n",
    "\n",
    "cv2.imshow(\"Original\", original)\n",
    "cv2.imshow(\"Processed\", processed)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
