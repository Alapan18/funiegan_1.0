{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_WakDenGmgW",
    "outputId": "1bc85e9c-9a2d-45b5-ba7c-f55d2cdf429b"
   },
   "outputs": [],
   "source": [
    "%cd C:/Users/alapa/funiegan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHEYOC7cK4bn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# pytorch libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "# local libs\n",
    "from PyTorch.nets.commons import Weights_Normal, VGG19_PercepLoss\n",
    "from PyTorch.nets.SNAttentionfuniegan import GeneratorFunieGAN, DiscriminatorFunieGAN\n",
    "from PyTorch.utils.data_utils import GetTrainingPairs, GetValImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bpxUYCnK4ZS"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cfg_file\", type=str, default=r\"PyTorch/configs/train_euvp.yaml\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=0, help=\"which epoch to start from\")\n",
    "parser.add_argument(\"--num_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=8, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0003, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of 1st order momentum\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.99, help=\"adam: decay of 2nd order momentum\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjYo-WeMK4Iu"
   },
   "outputs": [],
   "source": [
    "epoch = args.epoch\n",
    "num_epochs = args.num_epochs\n",
    "batch_size =  args.batch_size\n",
    "lr_rate, lr_b1, lr_b2 = args.lr, args.b1, args.b2\n",
    "# load the data config file\n",
    "with open(args.cfg_file) as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# get info from config file\n",
    "dataset_name = cfg[\"dataset_name\"]\n",
    "dataset_path = cfg[\"dataset_path\"]\n",
    "channels = cfg[\"chans\"]\n",
    "img_width = cfg[\"im_width\"]\n",
    "img_height = cfg[\"im_height\"]\n",
    "val_interval = cfg[\"val_interval\"]\n",
    "ckpt_interval = cfg[\"ckpt_interval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjCtxcO1RhVK",
    "outputId": "9c48701a-7239-4272-fe7a-76dbf14e793a"
   },
   "outputs": [],
   "source": [
    "\n",
    "print (dataset_name)\n",
    "print (dataset_path)\n",
    "print (channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOZK9M4xK4FJ"
   },
   "outputs": [],
   "source": [
    "## create dir for model and validation data\n",
    "samples_dir = os.path.join(\"samples/FunieGAN/\", dataset_name)\n",
    "checkpoint_dir = os.path.join(\"checkpoints/FunieGAN(A3)/\", dataset_name)\n",
    "os.makedirs(samples_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSOcWFz7K4C2"
   },
   "outputs": [],
   "source": [
    "Adv_cGAN = torch.nn.MSELoss()\n",
    "L1_G  = torch.nn.L1Loss() # similarity loss (l1)\n",
    "L_vgg = VGG19_PercepLoss() # content loss (vgg)\n",
    "lambda_1, lambda_con = 7, 3 # 7:3 (as in paper)\n",
    "patch = (1, img_height//16, img_width//16) # 16x16 for 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kd8IEfefK4AA"
   },
   "outputs": [],
   "source": [
    "generator = GeneratorFunieGAN()\n",
    "discriminator = DiscriminatorFunieGAN()\n",
    "\n",
    "# see if cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    Adv_cGAN.cuda()\n",
    "    L1_G = L1_G.cuda()\n",
    "    L_vgg = L_vgg.cuda()\n",
    "    Tensor = torch.cuda.FloatTensor\n",
    "else:\n",
    "    Tensor = torch.FloatTensor\n",
    "\n",
    "# Initialize weights or load pretrained models\n",
    "if args.epoch == 0:\n",
    "    generator.apply(Weights_Normal)\n",
    "    discriminator.apply(Weights_Normal)\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(\"checkpoints/FunieGAN(A3)/%s/generator_%d.pth\" % (dataset_name, args.epoch)))\n",
    "    discriminator.load_state_dict(torch.load(\"checkpoints/FunieGAN(A3)/%s/discriminator_%d.pth\" % (dataset_name, epoch)))\n",
    "    print (\"Loaded model from epoch %d\" %(epoch))\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr_rate, betas=(lr_b1, lr_b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr_rate, betas=(lr_b1, lr_b2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kceQwejiK39s",
    "outputId": "2f862cc0-a926-4b5b-9393-8383ad7cbb8d"
   },
   "outputs": [],
   "source": [
    "transforms_ = [\n",
    "    transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    GetTrainingPairs(dataset_path, dataset_name, transforms_=transforms_),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 16,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    GetValImage(dataset_path, dataset_name, transforms_=transforms_, sub_dir='validation'),\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnXdrPRLRhVM",
    "outputId": "b87b4e9e-91b8-4555-f16b-642c8e0a7720"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of samples in dataloader: {len(dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vN7EMzpCK37D",
    "outputId": "614a7e74-c490-4a9e-b240-3e3fce86da27"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epoch+1, num_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Model inputs\n",
    "        imgs_distorted = Variable(batch[\"A\"].type(Tensor))\n",
    "        imgs_good_gt = Variable(batch[\"B\"].type(Tensor))\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((imgs_distorted.size(0), *patch))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((imgs_distorted.size(0), *patch))), requires_grad=False)\n",
    "\n",
    "        ## Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        imgs_fake = generator(imgs_distorted)\n",
    "        pred_real = discriminator(imgs_good_gt, imgs_distorted)\n",
    "        loss_real = Adv_cGAN(pred_real, valid)\n",
    "        pred_fake = discriminator(imgs_fake, imgs_distorted)\n",
    "        loss_fake = Adv_cGAN(pred_fake, fake)\n",
    "        # Total loss: real + fake (standard PatchGAN)\n",
    "        loss_D = 0.5 * (loss_real + loss_fake) * 10.0 # 10x scaled for stability\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        ## Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        imgs_fake = generator(imgs_distorted)\n",
    "        pred_fake = discriminator(imgs_fake, imgs_distorted)\n",
    "        loss_GAN =  Adv_cGAN(pred_fake, valid) # GAN loss\n",
    "        loss_1 = L1_G(imgs_fake, imgs_good_gt) # similarity loss\n",
    "        loss_con = L_vgg(imgs_fake, imgs_good_gt)# content loss\n",
    "        # Total loss (Section 3.2.1 in the paper)\n",
    "        loss_G = loss_GAN + lambda_1 * loss_1  + lambda_con * loss_con\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        ## Print log\n",
    "        if not i%1:\n",
    "            sys.stdout.write(\"\\r[Epoch %d/%d: batch %d/%d] [DLoss: %.3f, GLoss: %.3f, AdvLoss: %.3f]\"\n",
    "                              %(\n",
    "                                epoch, num_epochs, i, len(dataloader),\n",
    "                                loss_D.item(), loss_G.item(), loss_GAN.item(),\n",
    "                               )\n",
    "            )\n",
    "        ## If at sample interval save image\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % val_interval == 0:\n",
    "            imgs = next(iter(val_dataloader))\n",
    "            imgs_val = Variable(imgs[\"val\"].type(Tensor))\n",
    "            imgs_gen = generator(imgs_val)\n",
    "            img_sample = torch.cat((imgs_val.data, imgs_gen.data), -2)\n",
    "            save_image(img_sample, \"samples/FunieGAN/%s/%s.png\" % (dataset_name, batches_done), nrow=5, normalize=True)\n",
    "\n",
    "    ## Save model checkpoints\n",
    "    torch.save(generator.state_dict(), \"checkpoints/FunieGAN(A3)/%s/generator_%d.pth\" % (dataset_name, epoch))\n",
    "    torch.save(discriminator.state_dict(), \"checkpoints/FunieGAN(A3)/%s/discriminator_%d.pth\" % (dataset_name, epoch))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
