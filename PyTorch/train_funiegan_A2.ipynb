{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_WakDenGmgW",
    "outputId": "1bc85e9c-9a2d-45b5-ba7c-f55d2cdf429b"
   },
   "outputs": [],
   "source": [
    "%cd C:/Users/alapa/funiegan/funiegan_1.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pHEYOC7cK4bn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# pytorch libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "# local libs\n",
    "from PyTorch.nets.commons import Weights_Normal, VGG19_PercepLoss\n",
    "from PyTorch.nets.SelfAttentionfuniegan import GeneratorFunieGAN, DiscriminatorFunieGAN\n",
    "from PyTorch.utils.data_utils import GetTrainingPairs, GetValImage\n",
    "from torch_optimizer import Lookahead\n",
    "from torch_optimizer import NovoGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1bpxUYCnK4ZS"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cfg_file\", type=str, default=r\"PyTorch/configs/train_euvp.yaml\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=0, help=\"which epoch to start from\")\n",
    "parser.add_argument(\"--num_epochs\", type=int, default=400, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=8, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0001, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.9, help=\"adam: decay of 1st order momentum\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of 2nd order momentum\")\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xjYo-WeMK4Iu"
   },
   "outputs": [],
   "source": [
    "epoch = args.epoch\n",
    "num_epochs = args.num_epochs\n",
    "batch_size =  args.batch_size\n",
    "lr_rate, lr_b1, lr_b2 = args.lr, args.b1, args.b2\n",
    "# load the data config file\n",
    "with open(args.cfg_file) as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# get info from config file\n",
    "dataset_name = cfg[\"dataset_name\"]\n",
    "dataset_path = cfg[\"dataset_path\"]\n",
    "channels = cfg[\"chans\"]\n",
    "img_width = cfg[\"im_width\"]\n",
    "img_height = cfg[\"im_height\"]\n",
    "val_interval = cfg[\"val_interval\"]\n",
    "ckpt_interval = cfg[\"ckpt_interval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjCtxcO1RhVK",
    "outputId": "9c48701a-7239-4272-fe7a-76dbf14e793a"
   },
   "outputs": [],
   "source": [
    "\n",
    "print (dataset_name)\n",
    "print (dataset_path)\n",
    "print (channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZOZK9M4xK4FJ"
   },
   "outputs": [],
   "source": [
    "## create dir for model and validation data\n",
    "samples_dir = os.path.join(\"samples2/FunieGAN/\", dataset_name)\n",
    "checkpoint_dir = os.path.join(\"checkpoints/FunieGAN(NovoLook)/\", dataset_name)\n",
    "os.makedirs(samples_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSOcWFz7K4C2"
   },
   "outputs": [],
   "source": [
    "Adv_cGAN = torch.nn.MSELoss()\n",
    "L1_G  = torch.nn.L1Loss() # similarity loss (l1)\n",
    "L_vgg = VGG19_PercepLoss() # content loss (vgg)\n",
    "lambda_1, lambda_con = 7, 3 # 7:3 (as in paper)\n",
    "patch = (1, img_height//16, img_width//16) # 16x16 for 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Kd8IEfefK4AA"
   },
   "outputs": [],
   "source": [
    "generator = GeneratorFunieGAN()\n",
    "discriminator = DiscriminatorFunieGAN()\n",
    "\n",
    "# see if cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    Adv_cGAN.cuda()\n",
    "    L1_G = L1_G.cuda()\n",
    "    L_vgg = L_vgg.cuda()\n",
    "    Tensor = torch.cuda.FloatTensor\n",
    "else:\n",
    "    Tensor = torch.FloatTensor\n",
    "\n",
    "# Initialize weights or load pretrained models\n",
    "if args.epoch == 0:\n",
    "    generator.apply(Weights_Normal)\n",
    "    discriminator.apply(Weights_Normal)\n",
    "else:\n",
    "    generator.load_state_dict(torch.load(\"checkpoints/FunieGAN(NovoLook)/%s/generator_%d.pth\" % (dataset_name, args.epoch)))\n",
    "    discriminator.load_state_dict(torch.load(\"checkpoints/FunieGAN(NovoLook)/%s/discriminator_%d.pth\" % (dataset_name, epoch)))\n",
    "    print (\"Loaded model from epoch %d\" %(epoch))\n",
    "\n",
    "# Optimizers\n",
    "base_optim_G = NovoGrad(generator.parameters(), lr=3*lr_rate, betas=(lr_b1, lr_b2))\n",
    "base_optim_D = NovoGrad(discriminator.parameters(), lr=0.1*lr_rate, betas=(lr_b1, lr_b2))\n",
    "optimizer_G = Lookahead(base_optim_G, k=5, alpha=0.5)\n",
    "optimizer_D = Lookahead(base_optim_D, k=5, alpha=0.5)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=15, gamma=0.85)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=20, gamma=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kceQwejiK39s",
    "outputId": "2f862cc0-a926-4b5b-9393-8383ad7cbb8d"
   },
   "outputs": [],
   "source": [
    "transforms_ = [\n",
    "    transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    GetTrainingPairs(dataset_path, dataset_name, transforms_=transforms_),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 16,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    GetValImage(dataset_path, dataset_name, transforms_=transforms_, sub_dir='validation'),\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnXdrPRLRhVM",
    "outputId": "b87b4e9e-91b8-4555-f16b-642c8e0a7720"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of samples in dataloader: {len(dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vN7EMzpCK37D",
    "outputId": "614a7e74-c490-4a9e-b240-3e3fce86da27"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m loss_G \u001b[38;5;241m=\u001b[39m loss_GAN \u001b[38;5;241m+\u001b[39m lambda_1 \u001b[38;5;241m*\u001b[39m loss_1  \u001b[38;5;241m+\u001b[39m lambda_con \u001b[38;5;241m*\u001b[39m loss_con\n\u001b[0;32m     32\u001b[0m loss_G\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 33\u001b[0m \u001b[43moptimizer_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m## Print log\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch_optimizer\\lookahead.py:74\u001b[0m, in \u001b[0;36mLookahead.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure: OptLossClosure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OptFloat:\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs a single optimization step.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m        closure: A closure that reevaluates the model and returns the loss.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch_optimizer\\novograd.py:141\u001b[0m, in \u001b[0;36mNovoGrad.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    139\u001b[0m     exp_avg_sq\u001b[38;5;241m.\u001b[39mcopy_(norm)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(norm, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# till now\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmax(max_exp_avg_sq, exp_avg_sq, out\u001b[38;5;241m=\u001b[39mmax_exp_avg_sq)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch+1, num_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Model inputs\n",
    "        imgs_distorted = Variable(batch[\"A\"].type(Tensor))\n",
    "        imgs_good_gt = Variable(batch[\"B\"].type(Tensor))\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((imgs_distorted.size(0), *patch))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((imgs_distorted.size(0), *patch))), requires_grad=False)\n",
    "\n",
    "        ## Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        imgs_fake = generator(imgs_distorted)\n",
    "        pred_real = discriminator(imgs_good_gt, imgs_distorted)\n",
    "        loss_real = Adv_cGAN(pred_real, valid)\n",
    "        pred_fake = discriminator(imgs_fake, imgs_distorted)\n",
    "        loss_fake = Adv_cGAN(pred_fake, fake)\n",
    "        # Total loss: real + fake (standard PatchGAN)\n",
    "        loss_D = 0.5 * (loss_real + loss_fake) * 10.0 # 10x scaled for stability\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        ## Train Generator\n",
    "        #for _ in range(4):\n",
    "        optimizer_G.zero_grad()\n",
    "        imgs_fake = generator(imgs_distorted)\n",
    "        pred_fake = discriminator(imgs_fake, imgs_distorted)\n",
    "        loss_GAN =  Adv_cGAN(pred_fake, valid) # GAN loss\n",
    "        loss_1 = L1_G(imgs_fake, imgs_good_gt) # similarity loss\n",
    "        loss_con = L_vgg(imgs_fake, imgs_good_gt)# content loss\n",
    "        # Total loss (Section 3.2.1 in the paper)\n",
    "        loss_G = loss_GAN + lambda_1 * loss_1  + lambda_con * loss_con\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        ## Print log\n",
    "        if not i%1:\n",
    "            sys.stdout.write(\"\\r[Epoch %d/%d: batch %d/%d] [DLoss: %.3f, GLoss: %.3f, AdvLoss: %.3f]\"\n",
    "                              %(\n",
    "                                epoch, num_epochs, i, len(dataloader),\n",
    "                                loss_D.item(), loss_G.item(), loss_GAN.item(),\n",
    "                               )\n",
    "            )\n",
    "        ## If at sample interval save image\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % val_interval == 0:\n",
    "            imgs = next(iter(val_dataloader))\n",
    "            imgs_val = Variable(imgs[\"val\"].type(Tensor))\n",
    "            imgs_gen = generator(imgs_val)\n",
    "            img_sample = torch.cat((imgs_val.data, imgs_gen.data), -2)\n",
    "            save_image(img_sample, \"samples2/FunieGAN/%s/%s.png\" % (dataset_name, batches_done), nrow=5, normalize=True)\n",
    "\n",
    "    ## Save model checkpoints\n",
    "    torch.save(generator.state_dict(), \"checkpoints/FunieGAN(NovoLook)/%s/generator_%d.pth\" % (dataset_name, epoch))\n",
    "    torch.save(discriminator.state_dict(), \"checkpoints/FunieGAN(NovoLook)/%s/discriminator_%d.pth\" % (dataset_name, epoch))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
