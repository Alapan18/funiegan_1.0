{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_WakDenGmgW",
        "outputId": "ff3cd0b3-7f88-416d-be5b-2268b66c3cd5"
      },
      "outputs": [],
      "source": [
        "%cd C:/Users/alapa/funiegan/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import argparse\n",
        "from torchvision import transforms\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from IPython.display import display\n",
        "from os.path import exists\n",
        "\n",
        "print(\"upload image\")\n",
        "# Create a Tkinter window\n",
        "root = tk.Tk()\n",
        "# Hide the main window\n",
        "\n",
        "# Prompt the user to select an image file\n",
        "file_path = filedialog.askopenfilename(\n",
        "    filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.gif;*.bmp\")]\n",
        ")\n",
        "\n",
        "if not file_path:\n",
        "    print(\"No file selected. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "# Load the selected image\n",
        "img = Image.open(file_path)\n",
        "display(img)\n",
        "root.withdraw()\n",
        "\n",
        "print(\"image uploaded\")\n",
        "img_width, img_height, channels = 256, 256, 3\n",
        "transforms_ = [transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "transform = transforms.Compose(transforms_)\n",
        "\n",
        "path = \"EUVP/test_samples/single_result\"\n",
        "\n",
        "for i in range(0, 11):\n",
        "    generator = f\"checkpoints/FunieGAN/EUVP/generator_{i}.pth\"\n",
        "\n",
        "    # Argument parsing (if needed)\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model_name\", type=str, default=\"funiegan\")  # or \"ugan\"\n",
        "    parser.add_argument(\"--model_path\", type=str, default=generator)\n",
        "    opt, unknown = parser.parse_known_args()\n",
        "\n",
        "    print(opt.model_path)\n",
        "\n",
        "    # Check if model exists\n",
        "    assert exists(opt.model_path), \"model not found\"\n",
        "    is_cuda = torch.cuda.is_available()\n",
        "    Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor \n",
        "\n",
        "    if opt.model_name.lower()=='funiegan':\n",
        "        from PyTorch.nets import funiegan\n",
        "        model = funiegan.GeneratorFunieGAN()\n",
        "    elif opt.model_name.lower()=='ugan':\n",
        "        from nets.ugan import UGAN_Nets\n",
        "        model = UGAN_Nets(base_model='pix2pix').netG\n",
        "    else: \n",
        "        # other models\n",
        "        continue\n",
        "\n",
        "    model.load_state_dict(torch.load(opt.model_path))\n",
        "    if is_cuda: model.cuda()\n",
        "    model.eval()\n",
        "    print (\"Loaded model from %s\" % (opt.model_path))\n",
        "    \n",
        "    inp_img = transform(img)\n",
        "    inp_img = Variable(inp_img).type(Tensor).unsqueeze(0)\n",
        "    \n",
        "    # Generate enhanced image\n",
        "    with torch.no_grad():\n",
        "        gen_img = model(inp_img)\n",
        "\n",
        "    # Convert tensors to PIL images for display\n",
        "    inp_img_pil = transforms.ToPILImage()(inp_img.squeeze(0).cpu())\n",
        "    gen_img_pil = transforms.ToPILImage()(gen_img.squeeze(0).cpu())\n",
        "\n",
        "    # Display input and generated images side by side\n",
        "    display(inp_img_pil)\n",
        "    display(gen_img_pil)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bpxUYCnK4ZS"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from torchvision import transforms\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from IPython.display import display\n",
        "from torchvision.utils import save_image\n",
        "from os.path import exists\n",
        "\n",
        "print(\"upload image\")\n",
        "# Create a Tkinter window\n",
        "root = tk.Tk()\n",
        "# Hide the main window\n",
        "\n",
        "# Prompt the user to select an image file\n",
        "file_path = filedialog.askopenfilename(\n",
        "    filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.gif;*.bmp\")]\n",
        ")\n",
        "\n",
        "if not file_path:\n",
        "    print(\"No file selected. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "# Load the selected image\n",
        "img = Image.open(file_path)\n",
        "display(img)\n",
        "root.withdraw()\n",
        "\n",
        "print(\"image uploaded\")\n",
        "img_width, img_height, channels = 256, 256, 3\n",
        "transforms_ = [transforms.Resize((img_height, img_width), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]\n",
        "transform = transforms.Compose(transforms_)\n",
        "\n",
        "path = \"EUVP/test_samples/single_result\"\n",
        "\n",
        "for i in range(0, 11):\n",
        "    generator = f\"checkpoints/FunieGAN/EUVP/generator_{i}.pth\"\n",
        "\n",
        "    # Argument parsing (if needed)\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model_name\", type=str, default=\"funiegan\")  # or \"ugan\"\n",
        "    parser.add_argument(\"--model_path\", type=str, default=generator)\n",
        "    opt, unknown = parser.parse_known_args()\n",
        "\n",
        "    print(opt.model_path)\n",
        "\n",
        "    # Check if model exists\n",
        "    assert exists(opt.model_path), \"model not found\"\n",
        "    is_cuda = torch.cuda.is_available()\n",
        "    Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor \n",
        "\n",
        "    if opt.model_name.lower()=='funiegan':\n",
        "        from PyTorch.nets import funiegan\n",
        "        model = funiegan.GeneratorFunieGAN()\n",
        "    elif opt.model_name.lower()=='ugan':\n",
        "        from nets.ugan import UGAN_Nets\n",
        "        model = UGAN_Nets(base_model='pix2pix').netG\n",
        "    else: \n",
        "        # other models\n",
        "        continue\n",
        "\n",
        "    model.load_state_dict(torch.load(opt.model_path))\n",
        "    if is_cuda: model.cuda()\n",
        "    model.eval()\n",
        "    print (\"Loaded model from %s\" % (opt.model_path))\n",
        "    \n",
        " \n",
        "    inp_img = transform(img) \n",
        "    inp_img = Variable(inp_img).type(Tensor).unsqueeze(0)\n",
        "    \n",
        "    # Generate enhanced image\n",
        "    with torch.no_grad():\n",
        "        gen_img = model(inp_img)\n",
        "\n",
        "    img_sample = torch.cat((inp_img.data, gen_img.data), -1)\n",
        "    display(img_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
